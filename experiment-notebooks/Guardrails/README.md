# Core/Guardrails

Experiments and demos for using guardrails and safety mechanisms in LLM applications.

## üìÑ Files in this folder

| File                                 | Description                                                                                   |
|--------------------------------------|-----------------------------------------------------------------------------------------------|
| `Introduction_to_Guardrails.ipynb`   | Jupyter notebook introducing the NemoGuardrails library for LLM safety and policy enforcement. |
| `Using_discriminator_guardrails_v2.ipynb` | Notebook demonstrating advanced guardrails and discriminator flows for LLMs using NemoGuardrails and LangChain. |

## üöÄ Overview

This folder contains notebooks that demonstrate how to use [NemoGuardrails](https://github.com/nvidia/NeMo-Guardrails) and related tools to add safety, policy, and discriminator guardrails to LLM-powered applications. The examples show YAML and colang configuration, self-check flows, and integration with LangChain.

### Key Features
- LLM safety and policy enforcement
- Discriminator guardrails and self-check flows
- Integration with LangChain and OpenAI models
- YAML and colang configuration examples

## üõ†Ô∏è Technologies Used
- Python
- Jupyter Notebook
- NemoGuardrails
- LangChain
- OpenAI API

## ‚ñ∂Ô∏è How to Use
1. Open the notebooks in Jupyter or Colab.
2. Follow the cells to install dependencies and review guardrail configurations.
3. Run the examples to see guardrails in action.

## üìÑ License
This folder follows the main repository's MIT License. See the root `LICENSE` file for details. 