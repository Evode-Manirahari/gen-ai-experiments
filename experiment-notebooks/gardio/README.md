# Core/gardio

A folder for experiments and demos using Gradio and Ollama for chat-based AI interfaces.

## üìÑ Files in this folder

| File                    | Description                                                                 |
|-------------------------|-----------------------------------------------------------------------------|
| `gradio_ollama_chat.py` | Python script for a Gradio chat interface powered by the Llama 3.2 model using LangChain and Ollama. |

## üöÄ Overview

This folder contains a demo script for building a conversational AI chat interface using [Gradio](https://gradio.app/) and the [Ollama](https://ollama.com/) Llama 3.2 model via LangChain. The script sets up a simple web-based chat where users can interact with the Llama model in real time.

### Key Features
- Gradio web chat interface
- Uses Llama 3.2 model via LangChain and Ollama
- Maintains chat history and context
- Easy to run and extend

## üõ†Ô∏è Technologies Used
- Python
- Gradio
- LangChain
- Ollama (Llama 3.2)

## ‚ñ∂Ô∏è How to Use
1. Install the required dependencies (see script for details).
2. Run `gradio_ollama_chat.py`:
   ```bash
   python gradio_ollama_chat.py
   ```
3. Open the Gradio web interface in your browser and start chatting!

## üìÑ License
This folder follows the main repository's MIT License. See the root `LICENSE` file for details. 