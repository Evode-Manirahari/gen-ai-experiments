{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHPrA32lncLv"
      },
      "source": [
        "##Get Started with SUTRA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GO4guros2wM"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1YULYifEf4HnUQGqTkph_nvJ1wiF9LXFc?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa35PCRexyQW"
      },
      "source": [
        "<img src=\"https://avatars.githubusercontent.com/u/87552521?s=200&v=4\" width=\"150\">\n",
        "\n",
        "SUTRA is a family of large multi-lingual language (LMLMs) models pioneered by Two Platforms. SUTRA’s dual-transformer approach extends the power of both MoE and Dense AI language model architectures, delivering cost-efficient multilingual capabilities for over 50+ languages. It powers scalable AI applications for conversation, search, and advanced reasoning, ensuring high-performance across diverse languages, domains and applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0g78hWpWaef"
      },
      "source": [
        "## Sutra using OpenAI SDK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpj_9ESOq-u7"
      },
      "source": [
        "###Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9cKviacDqNa",
        "outputId": "3bf4afeb-ac0a-4e51-eef0-a9aa9a27ff53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/606.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m604.2/606.1 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m606.1/606.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vP1n8Ho8q5FP"
      },
      "source": [
        "###Example Using OpenAI SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4jX3otJFKUV",
        "outputId": "0949b7e0-5ac7-4ce1-cccd-fce1ff99158e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I am SUTRA, an intelligent multilingual AI model designed to assist with a variety of tasks and provide information across different topics. How can I help you today?\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(base_url='https://api.two.ai/v2',\n",
        "                api_key=userdata.get(\"SUTRA_API_KEY\"))\n",
        "\n",
        "response = client.chat.completions.create(model='sutra-v2',\n",
        "                                        messages = [{\"role\": \"user\", \"content\": \"Who are you?\"}],\n",
        "                                        max_tokens=1024,\n",
        "                                        temperature=0)\n",
        "\n",
        "\n",
        "responce = response.choices[0].message.content\n",
        "print(responce)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUoVff7joQmc"
      },
      "source": [
        "###Example Using Diffrent Languages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeO1Mgg9uxUe"
      },
      "source": [
        "####Telugu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-GjPtamIOnA",
        "outputId": "677d3080-d4ef-4108-cfb9-d21e060f561b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ఒక గ్రామంలో ఒక చిన్న పిల్లవాడు ఉండేవాడు. అతని పేరు రాము. రాము చాలా చురుకైన, తెలివైన పిల్లవాడు. కానీ, అతనికి ఒక పెద్ద కల ఉంది - ఆకాశంలో ఎగిరే పక్షుల్లా ఎగరడం.\n",
            "\n",
            "ఒక రోజు, రాము తన స్నేహితులతో కలిసి అడవిలోకి వెళ్లాడు. అక్కడ, అతను ఒక పాత మాంత్రికుడిని చూసాడు. మాంత్రికుడు రాముకు దగ్గరగా వచ్చి, \"నువ్వు ఎగరాలంటే, నువ్వు ఈ మాంత్రిక బాటలు వేసుకోవాలి\" అని చెప్పాడు. రాము ఆశ్చర్యపోయాడు, కానీ అతను ప్రయత్నించడానికి సిద్ధంగా ఉన్నాడు.\n",
            "\n",
            "మాంత్రికుడు రాముకు కొన్ని మాంత్రిక వస్తువులను ఇచ్చాడు. \"ఈ వస్తువులను ఉపయోగించి, నువ్వు నీ కలను నిజం చేసుకోగలవు\" అని చెప్పాడు. రాము ఆనందంగా వాటిని తీసుకున్నాడు. \n",
            "\n",
            "అతను ఇంటికి తిరిగి వచ్చి, మాంత్రికుడిచ్చిన వస్తువులను ఉపయోగించి, ఎగరడం నేర్చుకోవాలని ప్రయత్నించాడు. మొదట, అతను విఫలమయ్యాడు, కానీ అతను నిరంతరం ప్రయత్నిస్తూ, చివరకు విజయవంతమయ్యాడు. \n",
            "\n",
            "రాము ఆకాశంలో ఎగిరి, తన స్నేహితులకు చూపించాడు. అందరూ ఆశ్చర్యపోయారు. రాము తన కలను నిజం చేసుకున్నాడు. \n",
            "\n",
            "ఈ కథ ద్వారా మనకు తెలుసు, కష్టపడితే, కలలు నిజమవుతాయి.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(base_url='https://api.two.ai/v2',\n",
        "                api_key=userdata.get(\"SUTRA_API_KEY\"))\n",
        "\n",
        "response = client.chat.completions.create(model='sutra-v2',\n",
        "                                        messages = [{\"role\": \"user\", \"content\": \"తెలుగులో ఒక కథ చెప్పు?\"}],\n",
        "                                        max_tokens=1024,\n",
        "                                        temperature=0)\n",
        "\n",
        "\n",
        "responce = response.choices[0].message.content\n",
        "print(responce)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA75BpNCrZGM"
      },
      "source": [
        "####French"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6MRRTYOrUSh",
        "outputId": "369922cc-6c45-438e-b584-fda58d0999ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Il était une fois, dans un petit village niché au cœur des montagnes, une jeune fille nommée Élodie. Élodie était connue pour sa curiosité insatiable et son amour de la nature. Chaque jour, elle explorait les forêts environnantes, découvrant des fleurs rares et écoutant le chant des oiseaux.\n",
            "\n",
            "Un matin, alors qu'elle se promenait près d'un ruisseau scintillant, Élodie aperçut une lumière étrange émanant d'une grotte. Intriguée, elle s'approcha et découvrit une pierre précieuse, brillante comme mille étoiles. En la touchant, elle sentit une énergie douce et chaleureuse l'envahir.\n",
            "\n",
            "Soudain, un vieux sage apparut devant elle. Il lui expliqua que cette pierre avait le pouvoir de réaliser un vœu, mais qu'il fallait l'utiliser avec sagesse. Élodie réfléchit longuement. Elle aurait pu demander richesse ou gloire, mais elle choisit plutôt de faire un vœu pour protéger la nature de son village, afin que les générations futures puissent en profiter.\n",
            "\n",
            "Le sage sourit et, d'un geste de la main, transforma la pierre en une lumière éclatante qui enveloppa le village. Depuis ce jour, la nature prospéra, et les habitants apprirent à vivre en harmonie avec leur environnement. Élodie devint une gardienne de la forêt, transmettant son amour pour la nature aux enfants du village.\n",
            "\n",
            "Ainsi, grâce à son vœu, Élodie changea non seulement sa vie, mais aussi celle de toute sa communauté, prouvant que la véritable richesse réside dans la préservation de notre monde.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(base_url='https://api.two.ai/v2',\n",
        "                api_key=userdata.get(\"SUTRA_API_KEY\"))\n",
        "\n",
        "response = client.chat.completions.create(model='sutra-v2',\n",
        "                                        messages = [{\"role\": \"user\", \"content\": \"Une histoire en français, s'il vous plaît.\"}],\n",
        "                                        max_tokens=1024,\n",
        "                                        temperature=0)\n",
        "\n",
        "\n",
        "responce = response.choices[0].message.content\n",
        "print(responce)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AwWaP94rnAx"
      },
      "source": [
        "####Marathi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kU21Golrorz",
        "outputId": "669cd17a-9302-4ec7-9a22-09861f918685"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "एकदा एक छोटा गाव होता, जिथे सर्व लोक एकमेकांच्या मदतीला सदैव तत्पर असत. त्या गावात एक गरीब शेतकरी, रामू, राहत होता. त्याच्याकडे एक छोटीशी जमीन होती, पण त्याच्या मेहनतीमुळे तो चांगले पीक उगवत होता.\n",
            "\n",
            "एक दिवस, रामूच्या शेतात एक सुंदर आणि मोठा सोनेरी फुलांचा झाड उगवला. तो झाड पाहून रामू खूप आनंदित झाला. त्याने ठरवले की तो या झाडाची काळजी घेईल आणि त्याला वाढवेल. प्रत्येक दिवशी तो झाडाला पाणी देत असे, त्याच्या आजूबाजूला गवत कापत असे आणि त्याला प्रेमाने बोलत असे.\n",
            "\n",
            "काही महिन्यांनंतर, त्या झाडावर अनेक सुंदर फुलं उमलली. गावातील लोक त्या फुलांची प्रशंसा करू लागले. रामूच्या मेहनतीमुळे झाडाने एक अद्भुत सौंदर्य प्राप्त केले होते. लोक त्याच्या शेतात येऊन त्या फुलांचा आनंद घेत होते.\n",
            "\n",
            "एक दिवस, गावात एक व्यापारी आला. त्याने त्या फुलांचे सौंदर्य पाहिले आणि रामूला विचारले, \"हे फुल तुम्ही विकणार का?\" रामूने उत्तर दिले, \"हे फुल माझ्या मेहनतीचे प्रतीक आहे, मी ते विकणार नाही.\" व्यापारीने त्याला पैसे देण्याची ऑफर दिली, पण रामूने नकार दिला.\n",
            "\n",
            "रामूच्या प्रेमाने आणि मेहनतीने त्या झाडाने गावात एक नवीन आशा निर्माण केली. लोकांनी त्याला प्रेरणा मानली आणि त्यांनीही आपल्या कामात अधिक मेहनत करण्याचा संकल्प केला. रामूच्या कथा गावात सर्वत्र पसरली आणि तो एक आदर्श बनला.\n",
            "\n",
            "या प्रकारे, रामूने दाखवले की प्रेम, मेहनत आणि समर्पणामुळे कोणतीही गोष्ट साधता येते.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(base_url='https://api.two.ai/v2',\n",
        "                api_key=userdata.get(\"SUTRA_API_KEY\"))\n",
        "\n",
        "response = client.chat.completions.create(model='sutra-v2',\n",
        "                                        messages = [{\"role\": \"user\", \"content\": \"कृपया मराठीत एक कथा सांगा\"}],\n",
        "                                        max_tokens=1024,\n",
        "                                        temperature=0)\n",
        "\n",
        "\n",
        "responce = response.choices[0].message.content\n",
        "print(responce)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kThbptYWWcB"
      },
      "source": [
        "## Sutra using Langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjJ7TWpQp8Zr"
      },
      "source": [
        "###install Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbvOcoZfWWK3",
        "outputId": "9ccd3737-7d9b-4b9f-b6ee-7ee5841d81c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain_openai langchain_community"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNo8k_shqAgb"
      },
      "source": [
        "###Example Using Langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZFgU-PiITE7",
        "outputId": "cdf044c7-61d7-48af-c602-5fb38d01ced8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "मैं ठीक हूँ, धन्यवाद! आप कैसे हैं? कोई विशेष विषय है जिस पर आप चर्चा करना चाहेंगे?\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "# Initialize the ChatOpenAI model\n",
        "chat = ChatOpenAI(\n",
        "    api_key=userdata.get(\"SUTRA_API_KEY\"),\n",
        "    base_url=\"https://api.two.ai/v2\",\n",
        "    model=\"sutra-v2\"\n",
        ")\n",
        "\n",
        "# Create a conversation\n",
        "messages = [HumanMessage(content=\"कैसे हो?\")]\n",
        "\n",
        "# Get response\n",
        "response = chat.invoke(messages)\n",
        "\n",
        "# Print response content\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRh5kY8nr3Nh"
      },
      "source": [
        "###Test With Multiple Languages using Langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QshNHf1_r7Ya",
        "outputId": "811164d5-7fe9-4c15-b7c5-62585e3ea094"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "# Initialize the ChatOpenAI model\n",
        "chat = ChatOpenAI(\n",
        "    api_key=userdata.get(\"SUTRA_API_KEY\"),\n",
        "    base_url=\"https://api.two.ai/v2\",\n",
        "    model=\"sutra-v2\",\n",
        "\n",
        ")\n",
        "\n",
        "# List of messages in different languages\n",
        "messages_list = [\n",
        "    HumanMessage(content=\"తెలుగులో ఒక కథ చెప్పు?\"),  # Telugu: \"Tell a story in Telugu\"\n",
        "    HumanMessage(content=\"Une histoire en français, s'il vous plaît.\"),  # French: \"A story in French, please.\"\n",
        "    HumanMessage(content=\"Por favor, cuéntame una historia en español.\"),  # Spanish: \"Please tell me a story in Spanish.\"\n",
        "    HumanMessage(content=\"कृपया हिंदी में एक कहानी सुनाइए।\"),  # Hindi: \"Please tell a story in Hindi.\"\n",
        "    HumanMessage(content=\"Bitte erzähle mir eine Geschichte auf Deutsch.\")  # German: \"Please tell me a story in German.\"\n",
        "]\n",
        "\n",
        "# Loop through each language request\n",
        "for msg in messages_list:\n",
        "    response = chat.invoke([msg])\n",
        "    print(f\"\\nPrompt: {msg.content}\")\n",
        "    print(f\"Response: {response.content}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYOG_JzstcHi"
      },
      "source": [
        "###Building a Simple Chatbot with Langchain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lS5jNxALtYxO",
        "outputId": "dd91b865-4bb4-4613-b4d2-299bbcfce91b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "# Initialize the ChatOpenAI model\n",
        "chat = ChatOpenAI(\n",
        "    api_key=userdata.get(\"SUTRA_API_KEY\"),\n",
        "    base_url=\"https://api.two.ai/v2\",\n",
        "    model=\"sutra-v2\"\n",
        ")\n",
        "\n",
        "# Start the chatbot conversation loop\n",
        "print(\"Chatbot: Hello! Type 'exit' to end the conversation.\\n\")\n",
        "\n",
        "chat_history = []\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \")  # Get user input\n",
        "\n",
        "    if user_input.lower() == \"exit\":\n",
        "        print(\"Chatbot: Goodbye! 👋\")\n",
        "        break\n",
        "\n",
        "    # Add user message to chat history\n",
        "    chat_history.append(HumanMessage(content=user_input))\n",
        "\n",
        "    # Get response from AI\n",
        "    response = chat.invoke(chat_history)\n",
        "\n",
        "    # Print AI response\n",
        "    print(\"Chatbot:\", response.content)\n",
        "\n",
        "    # Add AI response to chat history\n",
        "    chat_history.append(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yx9jgs3f8TbA"
      },
      "source": [
        "##LlamaIndex with the SUTRA model for Document Querying"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw2dnzLu8bkr"
      },
      "source": [
        "####Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahZUEEUj7eyb",
        "outputId": "e9e4e8e4-3f0f-4790-cef1-0f9c9e65396d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.3/251.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU llama-index langchain_openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFAPXG_h8fE2"
      },
      "source": [
        "####Setup API Keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "8MFbxcTv78wz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDXinJnF8jCP"
      },
      "source": [
        "###Example Using LlamaIndex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5eIhtbH7i4_",
        "outputId": "59bfef92-28c3-44aa-f952-12216400a9a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SUTRA supports over 50 languages.\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "from llama_index.core import Settings\n",
        "from langchain_openai import ChatOpenAI\n",
        "from llama_index.core import Document\n",
        "\n",
        "# Initialize the ChatOpenAI model\n",
        "chat = ChatOpenAI(\n",
        "    api_key=userdata.get(\"SUTRA_API_KEY\"),\n",
        "    base_url=\"https://api.two.ai/v2\",\n",
        "    model=\"sutra-v2\"\n",
        ")\n",
        "\n",
        "\n",
        "# Sample text\n",
        "text = \"\"\"\n",
        "SUTRA is a family of large multi-lingual language (LMLMs) models pioneered by Two Platforms.\n",
        "SUTRA’s dual-transformer approach extends the power of both MoE and Dense AI language model architectures,\n",
        "delivering cost-efficient multilingual capabilities for over 50+ languages. It powers scalable AI applications for conversation, search,\n",
        "and advanced reasoning, ensuring high-performance across diverse languages, domains and applications.\n",
        "\"\"\"\n",
        "\n",
        "# Create a document\n",
        "doc = Document(text=text)\n",
        "\n",
        "# Build index\n",
        "index = VectorStoreIndex.from_documents([doc])\n",
        "\n",
        "# Query\n",
        "response = index.as_query_engine().query(\"How many languages does SUTRA support?\")\n",
        "print(response)  # Output: \"SUTRA supports 50+ languages.\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
